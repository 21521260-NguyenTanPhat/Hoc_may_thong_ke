{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-05 17:59:40 INFO  WordSegmenter:24 - Loading Word Segmentation model\n",
      "2024-05-05 17:59:40 INFO  PosTagger:23 - Loading POS Tagging model\n",
      "2024-05-05 17:59:42 INFO  NerRecognizer:34 - Loading NER model\n",
      "2024-05-05 17:59:50 INFO  DependencyParser:32 - Loading Dependency Parsing model\n",
      "Progress: 100%|\u001b[32m███████████████████████████▉\u001b[0m| 7783/7786 [00:35<00:00, 221.42it/s]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for tokenizer\n",
    "!python3 tokenizer/prepare-visfd.py \\\n",
    "    ./data/Train.csv \\\n",
    "    --out_dir ./tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K[00:00:00] Tokenize words                 ██████████████████ 7688     /     7688[00:00:00] Tokenize words                 ██████████████████ 0        /        0\n",
      "\u001b[2K[00:00:00] Count pairs                    ██████████████████ 7688     /     7688\n",
      "\u001b[2K[00:00:00] Compute merges                 ██████████████████ 5640     /     5640\n"
     ]
    }
   ],
   "source": [
    "# Build tokenizer\n",
    "!python3 tokenizer/build-tokenizer.py \\\n",
    "    ./tokenizer/feedbacks.txt \\\n",
    "    --out_dir ./tokenizer \\\n",
    "    --config_file ./config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-05 20:28:14 INFO  WordSegmenter:24 - Loading Word Segmentation model\n",
      "2024-05-05 20:28:15 INFO  PosTagger:23 - Loading POS Tagging model\n",
      "2024-05-05 20:28:16 INFO  NerRecognizer:34 - Loading NER model\n",
      "2024-05-05 20:28:24 INFO  DependencyParser:32 - Loading Dependency Parsing model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m██████████\u001b[0m| 7786/7786 [00:00<00:00, 61473.57it/s]\n",
      "100%|\u001b[32m██████████\u001b[0m| 7786/7786 [00:35<00:00, 219.92it/s]\n",
      "100%|\u001b[32m██████████\u001b[0m| 7786/7786 [00:03<00:00, 2159.94it/s]\n",
      "100%|\u001b[32m██████████\u001b[0m| 1112/1112 [00:00<00:00, 29980.11it/s]\n",
      "100%|\u001b[32m██████████\u001b[0m| 1112/1112 [00:04<00:00, 241.80it/s]\n",
      "100%|\u001b[32m██████████\u001b[0m| 1112/1112 [00:00<00:00, 2634.73it/s]\n",
      "100%|\u001b[32m██████████\u001b[0m| 2224/2224 [00:00<00:00, 64199.12it/s]\n",
      "100%|\u001b[32m██████████\u001b[0m| 2224/2224 [00:09<00:00, 231.31it/s]\n",
      "100%|\u001b[32m██████████\u001b[0m| 2224/2224 [00:00<00:00, 2302.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from modeling.modules import ViSFD_LSTM\n",
    "from modeling.losses import ViSFDLoss\n",
    "from modeling.dataset import ViSFDDataset\n",
    "import torch\n",
    "\n",
    "task = \"mtl\"\n",
    "\n",
    "train_set = ViSFDDataset(\"data/Train.csv\", task_type=task)\n",
    "val_set = ViSFDDataset(\"data/Dev.csv\", task_type=task)\n",
    "test_set = ViSFDDataset(\"data/Test.csv\", task_type=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ptdat/Desktop/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ViSFD_LSTM                               --\n",
       "├─Embedding: 1-1                         4,608,000\n",
       "├─LSTM: 1-2                              5,251,072\n",
       "├─Conv1d: 1-3                            81,936\n",
       "├─AdaptiveAvgPool1d: 1-4                 --\n",
       "├─AdaptiveMaxPool1d: 1-5                 --\n",
       "├─MTL_ViSFDClassifier: 1-6               --\n",
       "│    └─AspectClassifier: 2-1             --\n",
       "│    │    └─Linear: 3-1                  22,539\n",
       "│    └─PolarityClassifier: 2-2           --\n",
       "│    │    └─ModuleList: 3-2              61,470\n",
       "=================================================================\n",
       "Total params: 10,025,017\n",
       "Trainable params: 10,025,017\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer: Tokenizer = Tokenizer.from_file(\"./tokenizer/tokenizer.json\")\n",
    "model = ViSFD_LSTM(\n",
    "    tokenizer, \n",
    "    task_type=task, \n",
    "    embed_dim=768,\n",
    "    dropout=0.5,\n",
    "    lstm_hidden_size=512,\n",
    "    cnn_kernel_size=5,\n",
    "    cnn_out_channels=16,\n",
    "    pooling_out_size=64,\n",
    "    output_dropout=0.5,\n",
    "    output_hidden_size=64\n",
    ")\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mEpoch 1\u001b[0m\u001b[1m | Training Loss 0.4532\u001b[0m: 100%|\u001b[32m██████████\u001b[0m| 244/244 [00:15<00:00, 15.98it/s]\n",
      "\u001b[1mAspect F1 Evaluation\u001b[0m: 100%|\u001b[34m██████████\u001b[0m| 35/35 [00:00<00:00, 40.01it/s]\n",
      "\u001b[1mLoss Evaluation\u001b[0m: 100%|\u001b[34m██████████\u001b[0m| 35/35 [00:00<00:00, 55.60it/s]\n",
      "\u001b[1;34mEpoch 2\u001b[0m\u001b[1m | Training Loss 0.3515\u001b[0m:  99%|\u001b[32m█████████▉\u001b[0m| 241/244 [00:13<00:00, 17.79it/s]/home/ptdat/Desktop/venv/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;34mEpoch 2\u001b[0m\u001b[1m | Training Loss 0.5676\u001b[0m: 100%|\u001b[32m██████████\u001b[0m| 244/244 [00:13<00:00, 18.16it/s]\n",
      "\u001b[1mAspect F1 Evaluation\u001b[0m: 100%|\u001b[34m██████████\u001b[0m| 35/35 [00:00<00:00, 42.93it/s]\n",
      "\u001b[1mLoss Evaluation\u001b[0m: 100%|\u001b[34m██████████\u001b[0m| 35/35 [00:00<00:00, 56.83it/s]\n",
      "\u001b[1;34mEpoch 3\u001b[0m\u001b[1m | Training Loss 0.1598\u001b[0m: 100%|\u001b[32m██████████\u001b[0m| 244/244 [00:13<00:00, 18.02it/s]\n",
      "\u001b[1mAspect F1 Evaluation\u001b[0m: 100%|\u001b[34m██████████\u001b[0m| 35/35 [00:00<00:00, 44.33it/s]\n",
      "\u001b[1mLoss Evaluation\u001b[0m: 100%|\u001b[34m██████████\u001b[0m| 35/35 [00:00<00:00, 54.96it/s]\n",
      "\u001b[1;34mEpoch 4\u001b[0m\u001b[1m | Training Loss 0.2939\u001b[0m: 100%|\u001b[32m██████████\u001b[0m| 244/244 [00:13<00:00, 18.18it/s]\n",
      "\u001b[1mAspect F1 Evaluation\u001b[0m: 100%|\u001b[34m██████████\u001b[0m| 35/35 [00:00<00:00, 49.77it/s]\n",
      "\u001b[1mLoss Evaluation\u001b[0m: 100%|\u001b[34m██████████\u001b[0m| 35/35 [00:00<00:00, 55.94it/s]\n",
      "\u001b[1;34mEpoch 5\u001b[0m\u001b[1m | Training Loss 0.1548\u001b[0m: 100%|\u001b[32m██████████\u001b[0m| 244/244 [00:13<00:00, 18.34it/s]\n",
      "\u001b[1mAspect F1 Evaluation\u001b[0m: 100%|\u001b[34m██████████\u001b[0m| 35/35 [00:00<00:00, 44.10it/s]\n",
      "\u001b[1mLoss Evaluation\u001b[0m: 100%|\u001b[34m██████████\u001b[0m| 35/35 [00:00<00:00, 55.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from modeling.utils import train\n",
    "from modeling.metrics import AspectF1Score\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    loss_fn=ViSFDLoss(task_type=task),\n",
    "    optimizer=torch.optim.AdamW(model.parameters()),\n",
    "    train_set=train_set,\n",
    "    validation_set=val_set,\n",
    "    batch_size=32,\n",
    "    epochs=5,\n",
    "    metrics={\n",
    "        \"Aspect F1\": AspectF1Score(task_type=task, aspect_threshold=0.4)\n",
    "    },\n",
    "    device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'CAMERA': 'Positive',\n",
       "   'PRICE': 'Negative',\n",
       "   'GENERAL': 'Positive',\n",
       "   'PERFORMANCE': 'Positive',\n",
       "   'DESIGN': 'Positive',\n",
       "   'OTHERS': ''}],\n",
       " '{CAMERA#Positive};{DESIGN#Positive};{PRICE#Neutral};{GENERAL#Positive};{OTHERS};')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from modeling.utils import stl_decode, mtl_decode\n",
    "\n",
    "i = 27\n",
    "# x, y = next(iter(DataLoader(val_set, 2)))\n",
    "x, y = val_set[i]\n",
    "model.eval()\n",
    "y_hat = model(x)\n",
    "mtl_decode(y_hat), val_set.data.label[i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
